{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c3a5267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "from streamlit_lottie import st_lottie\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from flashtext import KeywordProcessor\n",
    "from pywsd.lesk import adapted_lesk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import requests\n",
    "import random\n",
    "import re\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "from rake_nltk import Rake\n",
    "\n",
    "r = Rake()\n",
    "\n",
    "\n",
    "\n",
    "# Function to load Lottie animations\n",
    "def load_lottie_url(url: str):\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        return None\n",
    "    return r.json()\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('popular')\n",
    "\n",
    "# Define the function to extract important words\n",
    "def getImportantWords(art):\n",
    "    r = Rake(stopwords=stopwords.words('english') + list(string.punctuation))\n",
    "    r.extract_keywords_from_text(art)\n",
    "    keyphrases = r.get_ranked_phrases_with_scores()\n",
    "    result = [keyphrase for _, keyphrase in keyphrases[:25]]  # Get the top 25 keyphrases\n",
    "    return result\n",
    "\n",
    "# Split the text into sentences\n",
    "def splitTextToSents(art):\n",
    "    s = [sent_tokenize(art)]\n",
    "    s = [y for x in s for y in x]\n",
    "    s = [sent.strip() for sent in s if len(sent) > 15]\n",
    "    return s\n",
    "\n",
    "# Map sentences to keywords\n",
    "def mapSents(impWords, sents):\n",
    "    processor = KeywordProcessor()\n",
    "    keySents = {}\n",
    "    for word in impWords:\n",
    "        keySents[word] = []\n",
    "        processor.add_keyword(word)\n",
    "    for sent in sents:\n",
    "        found = processor.extract_keywords(sent)\n",
    "        for each in found:\n",
    "            keySents[each].append(sent)\n",
    "    for key in keySents.keys():\n",
    "        temp = keySents[key]\n",
    "        temp = sorted(temp, key=len, reverse=True)\n",
    "        keySents[key] = temp\n",
    "    return keySents\n",
    "\n",
    "# Get the sense of the word\n",
    "def getWordSense(sent, word):\n",
    "    word = word.lower()\n",
    "    if len(word.split()) > 0:\n",
    "        word = word.replace(\" \", \"_\")\n",
    "    synsets = wn.synsets(word, 'n')\n",
    "    if synsets:\n",
    "        wup = max_similarity(sent, word, 'wup', pos='n')\n",
    "        adapted_lesk_output = adapted_lesk(sent, word, pos='n')\n",
    "        lowest_index = min(synsets.index(wup), synsets.index(adapted_lesk_output))\n",
    "        return synsets[lowest_index]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Get distractors from WordNet\n",
    "def getDistractors(syn, word):\n",
    "    dists = []\n",
    "    word = word.lower()\n",
    "    actword = word\n",
    "    if len(word.split()) > 0:\n",
    "        word.replace(\" \", \"_\")\n",
    "    hypernym = syn.hypernyms()\n",
    "    if len(hypernym) == 0:\n",
    "        return dists\n",
    "    for each in hypernym[0].hyponyms():\n",
    "        name = each.lemmas()[0].name()\n",
    "        if name == actword:\n",
    "            continue\n",
    "        name = name.replace(\"_\", \" \")\n",
    "        name = \" \".join(w.capitalize() for w in name.split())\n",
    "        if name is not None and name not in dists:\n",
    "            dists.append(name)\n",
    "    return dists\n",
    "\n",
    "# Get distractors from ConceptNet\n",
    "def getDistractors2(word):\n",
    "    word = word.lower()\n",
    "    actword = word\n",
    "    if len(word.split()) > 0:\n",
    "        word = word.replace(\" \", \"_\")\n",
    "    dists = []\n",
    "    url = f\"http://api.conceptnet.io/query?node=/c/en/{word}/n&rel=/r/PartOf&start=/c/en/{word}&limit=5\"\n",
    "    obj = requests.get(url).json()\n",
    "    for edge in obj['edges']:\n",
    "        link = edge['end']['term']\n",
    "        url2 = f\"http://api.conceptnet.io/query?node={link}&rel=/r/PartOf&end={link}&limit=10\"\n",
    "        obj2 = requests.get(url2).json()\n",
    "        for edge in obj2['edges']:\n",
    "            word2 = edge['start']['label']\n",
    "            if word2 not in dists and actword.lower() not in word2.lower():\n",
    "                dists.append(word2)\n",
    "    return dists\n",
    "\n",
    "\n",
    "# Load Lottie animation from a URL\n",
    "lottie_animation = load_lottie_url(\"https://lottie.host/a17cef35-9c09-474f-9c26-225130dab967/dWJO2lpTSY.json\")\n",
    "\n",
    "    \n",
    "# Streamlit App\n",
    "st.markdown(\"<h1 style='color: skyblue;'>MCQ Generator</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "# Description\n",
    "st.markdown(\"\"\"\n",
    "## Generate Multiple Choice Questions from Text\n",
    "This app allows you to generate multiple choice questions (MCQs) from any text you provide. \n",
    "Simply upload a text file, specify the number of questions, and click the \"Generate MCQs\" button.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Align the info button to the top right corner\n",
    "col1, col2 = st.columns([10, 2])\n",
    "with col1:\n",
    "    pass  # Empty column to adjust the layout\n",
    "\n",
    "with col2:\n",
    "    # Info button\n",
    "    if st.button(label= \"ℹ️ Info\", key='info_button', help=\"Click for info\"):\n",
    "        st.sidebar.title(\"Information\")\n",
    "        st.sidebar.markdown(\"\"\"\n",
    "        Our project, the MCQ Generator, automatically generates multiple-choice questions (MCQs) from uploaded text files. \n",
    "        It utilizes natural language processing techniques to extract important words, map them to sentences, and provide \n",
    "        distractors for each question, enhancing learning and assessment processes in various educational contexts. \n",
    "\n",
    "        **Team Members:**\n",
    "        -  Biswajit Kar\n",
    "        -  Vivek Sharma\n",
    "        -  Bishal Sarmah\n",
    "\n",
    "        **References:**\n",
    "        - [MCQ Generator Jupyter Notebook](https://github.com/vaishnaviverma/MCQ-Generator/blob/main/MCQG.ipynb)\n",
    "        - [Lottie Files](https://lottiefiles.com)\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "    \n",
    "# Display Lottie animation\n",
    "if lottie_animation:\n",
    "    st_lottie(lottie_animation, height=300, key=\"coding\")\n",
    "else:\n",
    "    st.error(\"Error loading Lottie animation. Please check the URL or try again later.\")\n",
    "    \n",
    "        \n",
    "\n",
    "## File upload handler for text files\n",
    "uploaded_file = st.file_uploader(\"Choose a text file\", type=\"txt\")\n",
    "if uploaded_file is not None:\n",
    "    text = uploaded_file.read().decode(\"utf-8\")\n",
    "    \n",
    "    num_mcqs = st.number_input(\"Enter the number of questions you want:\", min_value=1, value=5)\n",
    "\n",
    "    if st.button('Generate MCQs', key='generate_button'):\n",
    "        impWords = getImportantWords(text)\n",
    "        sents = splitTextToSents(text)\n",
    "        mappedSents = mapSents(impWords, sents)\n",
    "\n",
    "        mappedDists = {}\n",
    "        correctAnswers = {}\n",
    "\n",
    "        for each in impWords:\n",
    "            if each not in mappedSents or not mappedSents[each]:\n",
    "                continue\n",
    "            distractors = random.sample([k for k in impWords if k != each], 3)\n",
    "            mappedDists[each] = distractors\n",
    "\n",
    "        \n",
    "        iterator = 1  # To keep the count of the questions\n",
    "        for each in mappedDists:\n",
    "            if iterator > num_mcqs:\n",
    "                break  # exit the loop if the desired number of MCQs has been reached\n",
    "            if each not in mappedSents or not mappedSents[each]:  # Check if the keyword is not in mappedSents or if its list of sentences is empty\n",
    "                continue  # Skip this keyword if it's not found in mappedSents or has no mapped sentences\n",
    "            sent = mappedSents[each][0]\n",
    "            p = re.compile(each, re.IGNORECASE)  # Converts into regular expression for pattern matching\n",
    "            op = p.sub(\"________\", sent)  # Replaces the keyword with underscores(blanks)\n",
    "            correct_answer = each.capitalize()  # The correct answer\n",
    "            st.write(f\"**Question {iterator}**: {op}\")  # Prints the question along with a question number\n",
    "            options = [each.capitalize()] + mappedDists[each]  # Capitalizes the options\n",
    "            options = options[:4]  # Selects only 4 options\n",
    "            opts = ['a', 'b', 'c', 'd']\n",
    "            random.shuffle(options)  # Shuffle the options so that order is not always same\n",
    "            for i, ch in enumerate(options):\n",
    "                st.write(f\"\\t {opts[i]}) {ch}\") # Print the options\n",
    "            st.write(f\"**Correct Answer**: {correct_answer}\")  # Print the correct answer\n",
    "            st.write(\"\\n\")\n",
    "            iterator += 1  # Increase the counter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d031f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa361b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
